{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import ipdb\n",
    "import cPickle as pickle\n",
    "import itertools\n",
    "assert hashlib.md5(\"a\").hexdigest() == hashlib.md5(\"a\").hexdigest()\n",
    "\n",
    "# http://nlp.stanford.edu/IR-book/html/htmledition/near-duplicates-and-shingling-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shingle is 542\n",
    "docs = []\n",
    "docs.append(\"0 2 9 0 5 4 3 4 5 1 5 4 9\".split())\n",
    "docs.append(\"1 2 9 0 5 4 3 4 5 1 5 4 9\".split())\n",
    "docs.append(\"5 4 2 4 5 9 1 9 9 3 4 2 4\".split())\n",
    "docs.append(\"5 5 5 4 2 7 3 9 1 4 5 4 9\".split())\n",
    "docs.append(\"4 4 4 4 5 6 3 7 5 4 3 3 9\".split())\n",
    "docs.append(\"1 4 3 2 5 7 3 7 5 7 5 7 9\".split())\n",
    "docs.append(\"12 42 23 252 25 27 23 27 25 17 25 37 49\".split())\n",
    "\n",
    "def shingle(doc, n):\n",
    "    shingles = zip(*[doc[i:] for i in range(n)])\n",
    "    return [\" \".join(a) for a in shingles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doclen = len(shingle(docs[0], 2))\n",
    "HASH_LEN = 32\n",
    "ngram = 4\n",
    "iters = 100\n",
    "\n",
    "def make_pi():\n",
    "    pi = np.random.permutation(HASH_LEN)\n",
    "    with open(\"pi.p\", \"w\") as outf:\n",
    "        pickle.dump(pi, outf)\n",
    "    return None\n",
    "    \n",
    "def get_pi():\n",
    "    with open(\"pi.p\", \"r\") as outf:\n",
    "        return pickle.load(outf)\n",
    "\n",
    "def permute(h, pi):\n",
    "    '''permute h and return a hex string'''\n",
    "    assert len(h) == len(pi)\n",
    "    permute = \"\"\n",
    "    for c in range(HASH_LEN):\n",
    "        permute += h[np.where(pi == c)[0][0]]\n",
    "    return \"0x\" + permute\n",
    "\n",
    "def shingle_hash_permute_min(j, pi):\n",
    "    '''shingle doc j, hash shingles, permute the hashes'''\n",
    "    shingles = shingle(docs[j], ngram) # shingle\n",
    "    hdj = [hashlib.md5(s).hexdigest() for s in shingles] # hash\n",
    "    pi_d_j = [permute(h, pi) for h in hdj]\n",
    "    return int(min(pi_d_j), 16)\n",
    "\n",
    "def jaccard(a, b):\n",
    "    '''a and b are indexes on documents'''\n",
    "    return len(set(a).intersection(set(b)))/len(set(a).union(set(b)))\n",
    "\n",
    "def sanity_check(d1, d2):\n",
    "    '''as iters grows, this should be more and more like jaccard'''\n",
    "    equal = 0\n",
    "    for i in range(iters):\n",
    "        make_pi()\n",
    "        pi = get_pi()\n",
    "        pi_d = [shingle_hash_permute_min(j, pi) for j in range(len(docs))]\n",
    "        if pi_d[d1] == pi_d[d2]:\n",
    "            equal += 1\n",
    "    # These should be more or less the same, if this is working properly\n",
    "    # print \"fancy jaccard={}\\npoor man's jaccard {}\".format(equal/iters, jaccard(set(shingle(docs[d1], ngram)), set(shingle(docs[d2], ngram))))\n",
    "    return equal/iters, jaccard(set(shingle(docs[d1], ngram)), set(shingle(docs[d2], ngram)))\n",
    "    \n",
    "def sketch_docs():\n",
    "    '''get N (iters) sketches of docs'''\n",
    "    out = []\n",
    "    for i in range(iters):\n",
    "        pi = np.random.permutation(HASH_LEN) # assume for now docs are same size\n",
    "        out.append([(shingle_hash_permute_min(j, pi), j) for j in range(len(docs))])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): 0.59, (1, 4): 0.04}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "sketches = sketch_docs()\n",
    "overlap_check = defaultdict(list)\n",
    "for sketch in sketches:\n",
    "    for pairing in sketch:\n",
    "        hash_no, docno = pairing\n",
    "        overlap_check[hash_no].append(docno)\n",
    "\n",
    "candidates = [tuple(value) for (key, value) in overlap_check.items() if len(value) > 1]\n",
    "candidates = set(candidates)\n",
    "sketch_jacard = {}\n",
    "for c in candidates:\n",
    "    a, b = c\n",
    "    counts = 0\n",
    "    for s in sketches:\n",
    "        # print s[a], s[b]\n",
    "        if s[a][0] == s[b][0]:\n",
    "            counts += 1\n",
    "    sketch_jacard[c] = counts/len(sketches)\n",
    "\n",
    "print sketch_jacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00888076673164\n"
     ]
    }
   ],
   "source": [
    "'''another check: avg jaccard diff for all docs'''\n",
    "count = 0\n",
    "sum_ = 0\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        fancy_jac, regular_jac = sanity_check(i,j)\n",
    "        sum_ += abs(fancy_jac - regular_jac)\n",
    "        count += 1\n",
    "        \n",
    "print sum_/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:CoreNLP_PyWrapper:mode given as 'pos' so setting annotators: tokenize, ssplit, pos, lemma\n",
      "INFO:CoreNLP_PyWrapper:Starting java subprocess, and waiting for signal it's ready, with command: exec java -Xmx4g -XX:ParallelGCThreads=1 -cp '/Library/Python/2.7/site-packages/stanford_corenlp_pywrapper/lib/*:/Users/ahandler/stanford-corenlp-full-2015-04-20/*'      corenlp.SocketServer --outpipe /tmp/corenlp_pywrap_pipe_pypid=75646_time=1475375137.41  --configdict '{\"annotators\":\"tokenize, ssplit, pos, lemma\"}'\n",
      "INFO:CoreNLP_PyWrapper:Successful ping. The server has started.\n",
      "INFO:CoreNLP_PyWrapper:Subprocess is ready.\n"
     ]
    }
   ],
   "source": [
    "from stanford_corenlp_pywrapper import CoreNLP\n",
    "proc=CoreNLP(\"pos\", corenlp_jars=[\"/Users/ahandler/stanford-corenlp-full-2015-04-20/*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.73, 0.8181818181818182)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_check(0,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
